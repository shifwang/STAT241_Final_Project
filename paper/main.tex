%%
%% Copyright 2007, 2008, 2009 Elsevier Ltd
%%
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%%
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.2 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.2 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%%
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%%

%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%%
%%
%%
%% $Id: elsarticle-template-num.tex 4 2009-10-24 08:22:58Z rishi $
%%
%%
\documentclass[preprint,12pt,3p]{elsarticle}

%% Use the option review to obtain double line spacing
%% \documentclass[preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
%% \documentclass[final,1p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% if you use PostScript figures in your article
%% use the graphics package for simple commands
%% \usepackage{graphics}
%% or use the graphicx package for more complicated commands
%% \usepackage{graphicx}
%% or use the epsfig package if you prefer to use the old commands
%% \usepackage{epsfig}


\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{mathrsfs}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{grffile}

%% The lineno packages adds line numbers. Start line numbering with
%% \begin{linenumbers}, end it with \end{linenumbers}. Or switch it on
%% for the whole article with \linenumbers after \end{frontmatter}.
%% \usepackage{lineno}

%% natbib.sty is loaded by default. However, natbib options can be
%% provided with \biboptions{...} command. Following options are
%% valid:

%%   round  -  round parentheses are used (default)
%%   square -  square brackets are used   [option]
%%   curly  -  curly braces are used      {option}
%%   angle  -  angle brackets are used    <option>
%%   semicolon  -  multiple citations separated by semi-colon
%%   colon  - same as semicolon, an earlier confusion
%%   comma  -  separated by comma
%%   numbers-  selects numerical citations
%%   super  -  numerical citations as superscripts
%%   sort   -  sorts multiple citations according to order in ref. list
%%   sort&compress   -  like sort, but also compresses numerical citations
%%   compress - compresses without sorting
%%
%% \biboptions{comma,round}

% \biboptions{}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\D}{\mathscr{D}}
\newcommand{\N}{\mathscr{N}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\var}{\mathrm{var}}
\DeclareMathOperator*{\argmin}{\arg\!\min}

\newtheorem{conjecture}{Conjecture}
\newtheorem{theorem}{Theorem}
\newtheorem{experiment}{Experiment}

\journal{STAT 241A}

\begin{document}

\begin{frontmatter}

\title{A Novel Sampling Method Using Stochastic Gradient Descent}


\author{Yu Wang, 3031741324\\ Weixin Cai, 26954913}
%\address[label2]{Address Two\fnref{label4}}

\begin{abstract}
Stochastic gradient descent (SGD), under mild conditions, can be viewed as a Markov chain sampler. This relationship has been pointed out in a variety of papers \cite{kushner2012stochastic, bach2014adaptivity}. Although SGD has been extensively studied, its property as a Markov chain seems to be largely overlooked. What is its stationary distribution? What is its mixing time? How does its mixing time relate to its convergence rate? Studying these properties could offer a novel perspective to understand SGD.

Currently, there aren't a lot of schemes available to analyzing SGD's mixing time. Traditional ways includes coupling, diameter bounds, and bottle-neck ratio etc. (see \emph{Reversible Markov chains and random walks on graphs} by Aldous et al.\cite{aldous2002reversible}, and \emph{Markov chains and mixing times} by Levin et al.\cite{levin2009markov}). However, these methods are designed for the Markov chain on a graph and might not be able to be applied to SGD directly.

Our proposal is to bridge the gap between classical Markov chain analysis and SGD. Specifically,  we would like to explore mixing time related issues and obtain some novel theoretical and empirical findings on the mixing time of SGD (If successful). The hunch is that if SGD converges fast, it will have a low mixing time. This seems to be a novel perspective to understand SGD. Duchi et al.\cite{duchi2012ergodic} shows how the finite-sample convergence rate (expected convergence \& high-probability convergence) of stochastic sub-gradient descent depends on the mixing time of the process. If we can bound the mixing time, subsequently, we will be able to understand the convergence of this class of optimization techniques. Theoretical analysis as well as empirical experiments will be carried out to further explore this issue.

During the poster session, the proposed method seems to be a rediscovery of the Langevin MCMC sampling. 

Our group contains two people. The tentative plan is that Yu focuses on the theoretical exploration and Weixin focuses on the empirical experiments. The final report will be written together.
\end{abstract}

\begin{keyword}
%% keywords here, in the form: keyword \sep keyword
Stochastic gradient descent \sep Sampling \sep Metropolis-Hastings
%% MSC codes here, in the form: \MSC code \sep code
%% or \MSC[2008] code \sep code (2000 is the default)
\end{keyword}

\end{frontmatter}

%%
%% Start line numbering here if you want
%%
% \linenumbers
% ===================================================================================
\section{Introduction} % (fold)
\label{sec:introduction}

The posterior sampling method is used to great advantage by a board range of statistical methodologies, such as EM algorithm \citep{dempster1977maximum}. From the Bayesian point of view, E-step of the EM algorithm can be seen as calculating the posterior distribution of the parameters of interest \citep{Tanner_The_1987}. Another crucial arena of posterior sampling is Bayesian modeling. For example, \cite{Geman_Stochastic_1993} studied image restoration as a maximum a posteriori (MAP) problem on lattice graph. They proposed a Markov Random Field - Gibbs class of method for solving the posterior inference.

Typically, to implement such algorithms, one must be able to sample from the posterior distribution $p(\theta|y,z)$. In general, however, the posterior does not have closed form and sampling could be difficult and sometimes intractable. Various alternatives have been proposed such as Monte-Carlo method to approximate the posterior in EM algorithm \citep{Wei1990}. \cite{Tanner_The_1987} considered data augmentation approach for calculating posterior. Analysis of posterior is studied in \cite{Rubin_The_1981} as a Bayesian Bootstrap approach.

To formalize the goal, the observed data $y$ follows a probability distribution indexed by $\theta$ : $p(y | \theta)$. We want to generate i.i.d. samples
\begin{equation}
\label{eq:sample}
x\mathop \sim\limits^{i.i.d.} p(\theta |y)
\end{equation}

Our approach to the problem (\ref{eq:sample}) is related to classical stochastic gradient descent (SGD) algorithms \citep{Robbins_A_1951,Polyak_Acceleration_1992}, where one assumes access to samples $y_1, ..., y_n$ from the distribution $p$ and performs gradient updates using $\nabla \log p(\theta ;y)$. SGD is widely applied in statistical estimation and machine learning literature \citep{lecun2012efficient,Finkel_Efficient_2008}. Classical analysis of SGD focus on convergence in nature and generally do not provide result on its sampling distribution. Although it is shown that SGD, under mild conditions, can be viewed as a Markov chain \citep{kushner2012stochastic,bach2014adaptivity}. Very few previous work has analyzed SGD as sampling technique. When compared with other sampling methods like Metropolis-Hastings \citep{Metropolis1953}, our method utilizes only a subset of the dataset to calculate transition probability, while Metropolis-Hastings requires all samples to construct likelihood $p(x|\theta)$ and subsequently the posterior. This makes our approach more applicable to ``Big Data'' problems, when the sample size is usually in the order of millions, or even billions. Our method is also distinct from Metropolis-Hastings, a likelihood-based sampler, in that the SGD sampler is entirely based on the gradient of the target distribution.

The main result of this paper is that performing stochastic gradient steps with specifically chosen objective function, step size, and sampling rate results in a provably accurate and efficient sampling procedure for Bayesian posteriors. The convergence to the stationary distribution is governed by problem-dependent terms (namely the expected convergence time of SGD) familiar from previous results on Markov chain \citep{aldous2002reversible,levin2009markov}. Our xxx main results characterize the sampling distribution of SGD. In particular, we show that the sampling distribution converges to the desired distribution with high probability.

The remainder of the paper is organized as follows. The next section contains a description of the algorithm we analyze and our main technical results. Following that in Section 3, we show that the classic stochastic gradient descent can be viewed as a special case of our algorithm, and give numerical examples to demonstrate our result. We expand on these results and provide an upper bound of the mixing time throughout Section 4. We conclude with discussion in Section 5.

% section introduction (end)
% ===================================================================================
%% main text
\section{Main Theorems}

Define $\D(\R^p)$ to be the family of the density functions of smooth random variables in $\R^p$, i.e.,

\begin{equation}
\D(\R^p)\triangleq \{p(\bx)\Big| p\in C^1(\R^p),~p(\bx) \geq 0,~ \int_\bx p(\bx) = 1.\}
\end{equation}
Suppose we would like to sample from a distribution $p(\bx)\in \D(\R^p) \propto f(\bx)$. 
\begin{algorithm}[H]
{\small
Given $f(x)$, 
\begin{algorithmic}\caption{Stochastic gradient descent (oracle)}\label{Alg:SGD}
\STATE {\bf Initialize} $ \bx^0$ arbitrarily;
\WHILE{burn-in period}
\STATE draw $a^t$ from Gaussian distribution $\N(\nabla \log f(\bx^k), \Sigma^{t})$.
\STATE
$\bx^{k+1} \gets \bx^k + (2\Sigma^t)^{-1} a^t$;
\STATE $k\gets k+1$;
\ENDWHILE
\STATE return $\bx^k$.
\end{algorithmic}}
\end{algorithm}


Consider any $p(\bx)\in \D(\R^p)$, we have the following theorem:

\begin{conjecture}
For any $p(\bx)\in \D(\R^p)$, it is the stationary distribution of iterates in Algorithm 1 with parameter $(-\log p(\bx), \epsilon, 2\epsilon)$.
\end{conjecture}
\begin{proof}
Let's verify this theorem by checking the detailed balance condition. Denote $g(\by|\bx)$ to be the density function of the transition, because $\by = \bx - \alpha \nabla f(\bx^k) + \epsilon^t$ and $\epsilon^t\sim \N(0, \sigma^2)$, we know
\begin{equation}
g(\by|\bx) = (2\pi \sigma^2)^{-p/2} \exp(- \frac{\|\by - \bx + \alpha \nabla h(\bx)\|^2}{2\sigma^2}).
\end{equation}
Then the detailed balance condition is
\begin{equation}\label{Eq:detailBalance}
p(\bx^{k+1}) g(\bx^{k}|\bx^{k+1}) = p(\bx^{k}) g(\bx^{k+1}|\bx^{k}).
\end{equation}
Since we will only consider $\bx^k$ and $\bx^{k+1}$ in the proof. For notation ease, we denote $\bx^{k+1}$ as $\bx^+$.
In order to prove \ref{Eq:detailBalance}, we would like to show the ratio between LHS and RHS to be 1. To be more specific, we have (Recall that $\sigma^2 = \alpha$)
\begin{eqnarray}
\frac{p(\bx^{+}) g(\bx^{k}|\bx^{+})}{p(\bx^{k}) g(\bx^{+}|\bx^{k})} = & \exp(-h(\bx^{+}) - \frac{\|\bx^{k} - \bx^+ + \alpha \nabla h(\bx^{+})\|^2}{2\alpha} + h(\bx^{k}) + \frac{\|\bx^{+} - \bx^k + \alpha \nabla h(\bx^k)\|^2}{2\alpha}).
\end{eqnarray}
Note that
\[h(\bx^+) - h(\bx^k) = \frac{\nabla h(\bx^k) + \nabla h(\bx^+)}{2} \cdot (\bx^+ - \bx^k) + O(\|\bx^+ - \bx^k\|^2),
\]
and
\begin{eqnarray}
 & \frac{\|\bx^{k} - \bx^+ + \alpha \nabla h(\bx^{+})\|^2}{2\alpha} - \frac{\|\bx^{+} - \bx^k + \alpha \nabla h(\bx^k)\|^2}{2\alpha} \\
 =& -\frac{\nabla h(\bx^k) + \nabla h(\bx^+)}{2} \cdot (\bx^+ - \bx^k) + \alpha/2 \|\nabla h(\bx^+)\|^2 - \alpha/2 \|\nabla h(\bx^+)\|^2.
\end{eqnarray}
Here, $\|\bx^+ - \bx^k\|$ will be roughly no bigger than $\alpha$ because $\bx^+ = \bx^k - \alpha \nabla h(\bx^k) + \epsilon^k$.  Thus it means $O(\|\bx^+ - \bx^k\|) = O(\alpha^2)$. What's more, $\alpha/2 \|\nabla h(\bx^+)\|^2 - \alpha/2 \|\nabla h(\bx^+)\|^2 = O(\alpha^2)$.
Thus we know
\begin{eqnarray}
\log \frac{p(\bx^{+}) g(\bx^{k}|\bx^{+})}{p(\bx^{k}) g(\bx^{+}|\bx^{k})} = &O(\alpha^2).
\end{eqnarray}
Therefore, we know the detailed balance equality holds approximately especially when $\alpha$ is small.

When $h$ is a quadratic function, the detailed balance holds exactly.
\end{proof}

Note that this is only a rough deduction instead of an accurate proof. The problem of this deduction is two-fold. First, the equality only holds approximately. Second, SGD sampler's stationary distribution might not satisfy the detailed balance condition. Therefore, we would like to examine the stationary distribution of SGD empirically for some special cases.

\begin{experiment}
Take the density function of $X$ to be $f(x) \propto \exp(- x^4)$, let $2\sigma^2 = \epsilon = 0.005$, $x_0 = 1$, burning-in period is $1000$, waiting period is $1000$, the empirical histogram v.s. the desired histogram is plotted in Figure ???
\end{experiment}
\begin{figure}
    \centering
    \includegraphics[width=.3\textwidth]{../figure/case1_step_0.005_iter_1e3.png}
    \includegraphics[width=.3\textwidth]{../figure/case1_step_0.005_iter_1e4.png}
    \includegraphics[width=.3\textwidth]{../figure/case1_step_0.005_iter_1e5.png}
    \includegraphics[width=.3\textwidth]{../figure/case2_step_0.005_iter_1e3.png}
    \includegraphics[width=.3\textwidth]{../figure/case2_step_0.005_iter_1e4.png}
    \includegraphics[width=.3\textwidth]{../figure/case2_step_0.005_iter_1e5.png}
    \includegraphics[width=.3\textwidth]{../figure/case3_step_0.005_iter_1e3.png}
    \includegraphics[width=.3\textwidth]{../figure/case3_step_0.005_iter_1e4.png}
    \includegraphics[width=.3\textwidth]{../figure/case3_step_0.005_iter_1e5.png}
    \caption{Empirical stationary distribution using SGD. Different columns correspond to different samples sizes ($1e3$, $1e4$, and $1e5$). Different rows correspond to different distributions ($f_1(x) = \exp(-x^4)$, $f_2(x) = \exp(-(x^2 - 4)(x^2 - 1))$, $f_3(x) = \exp(-|x|)$.}
    \label{Fig:exp1}
\end{figure}
% ===================================================================================
\section{Sampling from posterior distribution}
Consider a statistical model fitting problem. Given $n$ samples $X_1,\ldots, X_n$ and an assumed model $P(X_1|\theta)$. The maximum likelihood estimate will be
\[
\hat{\theta} \in \argmin - \sum_{i=1}^n \log P(X_i|\theta).
\]
This can be solved by gradient descent on objective function $- \sum_{i=1}^n \log P(X_i|\theta)$. Now let's consider a Bayesian approach to estimate $\theta$ by maximizing its posterior probability given the data. The posterior distribution of $\theta$ is
\[
P(\theta|(X_1,\ldots, X_n)) = \frac{\prod_{i=1}^n P(X_i|\theta) P(\theta)}{P(X_1,\ldots, X_n)} \propto \prod_{i=1}^n P(X_i|\theta) P(\theta).
\]
By Conjecture 1, we could use SGD to draw samples using $(-\sum_i \log P(X_i|\theta) + \log P(\theta), \epsilon, 2\epsilon)$.  Note that the core update rule is
\[
\theta^{t+1} \gets \theta^{t} + \alpha (n^{-1} \sum_i \nabla \log P(X_i|\theta^t) - \log P(\theta^t)) + \epsilon^t.
\]
Note that $\alpha (n^{-1} \sum_{i=1}^n \nabla \log P(X_i|\theta^t) - \log P(\theta^t)) + \epsilon^t$ can be approximated by
\[
\sum_{i=1}^K (K^{-1} \nabla \log P(X_{\eta_i}|\theta^t) - \log P(\theta^t)),
\]
where $K$ is a constant smaller than $n$ and $\eta_i$ are IID drawn from $1,\ldots, n$. When $K\ll n$, this is much computational efficient. This relationship is elaborated in the following theorem:
\begin{theorem}[Central limit theorem]
Let $K$ be the subsampling size and $\eta_1,\ldots, \eta_K$ be samples drawing from $1,\ldots, n$ with replacement, then
\[
K^{-1}\sum_{i=1}^K (\nabla \log P(X_{\eta_i}|\theta^t) - \log P(\theta^t)) \sim \N(n^{-1} \nabla \log p(\theta) , K^{-1}\cov \nabla \log p(\theta)).
\]
\end{theorem}

\begin{algorithm}
{\small
Given data $X_1,\ldots, X_n$, model $p(X|\theta)$, sample size $K$
\begin{algorithmic}\caption{SGD based sampling}\label{Alg:SGD_Sampling}
\STATE {\bf Initialize} $ \theta^0$, $t \gets 0$;
\WHILE{stopping criterion not satisfied}
\STATE draw $K$ iid samples with replacement from $1,\ldots, n$, denoted $\eta_1,\ldots, \eta_K$.
\STATE calculate the mean $a^t$ and the covariance matrix $\Sigma^t$ of $(\nabla\log p(X_{\eta_i}|\theta^t))_{i=1}^K$.
\STATE
$\theta^{t+1} \gets \theta^t + 2(\Sigma^t)^{-1}a^t$;
\STATE $t\gets t+1$;
\ENDWHILE
\STATE return $\theta^k$.
\end{algorithmic}}
\end{algorithm}

\begin{experiment}
Consider the empirical/real density for $(\mu, \sigma^2)$ where $p(X_1|\mu, \sigma^2)\sim \N(\mu, \sigma^2)$, data $X_1,\ldots, X_{1000}$ is drawn from $\N(0, 1)$, $K = 1000$, sample size is $1000$. The empirical density is close to the real density. Note that variance $\sigma^2$ has higher variance than the expectation $\mu$
\end{experiment}
\begin{figure}
\includegraphics[width=0.5\linewidth]{../figure/simulation2_empirical.png}
\includegraphics[width=0.5\linewidth]{../figure/simulation2_real.png}
\caption{The empirical/real density for $(\mu, \sigma^2)$ where $p(X_1|\mu, \sigma^2)\sim \N(\mu, \sigma^2)$, data $X_1,\ldots, X_{1000}$ is drawn from $\N(0, 1)$, $K = 1000$, sample size is $1000$. The empirical density is close to the real density. Note that variance $\sigma^2$ has higher variance than the expectation $\mu$}
\end{figure}
% ===================================================================================
\section{Upper bound on the mixing time} % (fold)
\label{sec:upper_bound_on_the_mixing_time}
In order to analyze the efficiency of SGD, we need to consider its mixing time. If SGD's mixing time is small, we know it will be a very efficient sampling method. How to estimate its mixing time? In the past literature, the upperbound of a mixing time can be obtained by a coupling technique. Define $\|\cdot\|_{TV}$ to be the total variation norm of $\cdot$, $P^t(\bx^0)$ the density of $\bx^t$ starting from $\bx^0$, $d(t) = \max_{x\in \Omega} \|P^t(x, \cdot), \pi(\cdot)\|_{TV}$, and $\bar{d}(t) = \max_{x,y\in \Omega} \|P^t(x, \cdot), P^t(y,\cdot)\|_{TV}$. 
Define its mixing time to be 
\[
\tau_{\mathrm{mix}} \triangleq \min\{t|\max_{\bx^0}\|P^t(\bx^0) - p\|_{\mathrm{TV}}\leq 1/4\}.
\]


\begin{conjecture}[Upperbound for mixing time] Suppose $\tau_{\bx^0}$ is the stopping time when the algorithm converges to global minimum starting from $\bx^0$, we might be able to have a upper bound for $\tau_{\mathrm{mix}}$.
\[
\tau_{\mathrm{mix}} \leq 4 \max_{\bx^0}\E \tau_{\bx^0}.
\]
\end{conjecture}

So the conjecture is that when SGD converges fast, it will also be efficient as a sampling method.

% section upper_bound_on_the_mixing_time (end)

% ===================================================================================
\section{Discussion} % (fold)
\label{sec:discussion}


In this paper, we have shown that stochastic gradient descent approaches extend in an elegant way to a sampler for posterior distributions when computing the likelihood from the full data is intensive. We are able to establish the stationary distribution of the procedure and gave several examples showing the accuracy and uses of our result. By taking a Bayesian route, we are able to show that the SGD algorithm is a sampler of a posterior under a non-informative prior. This enables us to establish connection between SGD and maximum \emph{a posteriori} (MAP) procedure, which is an analogy to gradient descent solving a maximum likelihood estimator in the frequentist paradigm. A natural extension of this work, which we hope to be able to accomplish, is to derive finite sample rates of convergence for the mixing time, which would allow a more rigor understanding of the SGD family as a whole. Extensive simulation of the methodology is also needed to fully understand this novel SGD sampler.

A detailed contribution is summarized as the following:
\begin{enumerate}
    \item When the objective of SGD is chosen to be $\log f(x)$, the stationary distribution is approximately the same as $f(x)$. Empirical simulation shows even if $f(\cdot)$ has two modes, SGD sampler will still reach a pretty accurate distribution.
    \item When sampling from a posterior distribution, the SGD update step can be estimated using a randomly chosen subset of the whole dataset. A toy example of estimating the expectation and variance of a Gaussian distribution demonstrate its performance.
    \item We also carried out a comparison between SGD's mixing time and its convergence time. Empirical simulations show that when SGD converges fast, it will also have a small mixing time.
\end{enumerate}
Future work includes:
\begin{enumerate}
    \item we will dig into the literature on Langevin MCMC and learn more about this issue. 
    \item Current analysis cannot apply to the multiple-mode distribution. The simple simulation showed SGD, although very slow, still works in that case. Thus we might be able to consider this scenario in the future.
    \item The mixing time of SGD based sampling will be prohibitively large when multiple modes are present. We would also like to consider how to overcome this issue.
\end{enumerate}

\section{Acknowledgement}

We would like to thank Professor Martin Wainwright for his inspiring teaching this semester. And we also greatly appreciate Arturo Fernandez and Jeffery Chan, our GSIs, for their devotion in this course.

% section discussion (end)
\newpage
% ===================================================================================
%% The Appendices part is started with the command \appendix;
%% appendix sections are then done as normal sections
\appendix

\section{Section in Appendix}
\label{appendix-sec1}

Sample text. Sample text. Sample text. Sample text. Sample text. Sample text.
Sample text. Sample text. Sample text. Sample text. Sample text. Sample text.
Sample text.

%% References
%%
%% Following citation commands can be used in the body text:
%% Usage of \cite is as follows:
%%   \cite{key}         ==>>  [#]
%%   \cite[chap. 2]{key} ==>> [#, chap. 2]
%%

%% References with bibTeX database:

\bibliographystyle{elsarticle-num}
% \bibliographystyle{elsarticle-harv}
% \bibliographystyle{elsarticle-num-names}
% \bibliographystyle{model1a-num-names}
% \bibliographystyle{model1b-num-names}
% \bibliographystyle{model1c-num-names}
% \bibliographystyle{model1-num-names}
% \bibliographystyle{model2-names}
% \bibliographystyle{model3a-num-names}
% \bibliographystyle{model3-num-names}
% \bibliographystyle{model4-names}
% \bibliographystyle{model5-names}
% \bibliographystyle{model6-num-names}

\bibliography{sample}


\end{document}

%%
%% End of file `elsarticle-template-num.tex'.
