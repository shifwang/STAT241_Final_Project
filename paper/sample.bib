%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Wilson Cai at 2016-12-04 14:09:39 -0800 


%% Saved with string encoding Unicode (UTF-8) 



@article{duchi2012ergodic,
	Author = {Duchi, John C and Agarwal, Alekh and Johansson, Mikael and Jordan, Michael I},
	Journal = {SIAM Journal on Optimization},
	Number = {4},
	Pages = {1549--1578},
	Publisher = {SIAM},
	Title = {Ergodic mirror descent},
	Volume = {22},
	Year = {2012}}

@book{aldous2002reversible,
	Author = {Aldous, David and Fill, Jim},
	Publisher = {Berkeley},
	Title = {Reversible Markov chains and random walks on graphs},
	Year = {2002}}

@book{levin2009markov,
	Author = {Levin, David Asher and Peres, Yuval and Wilmer, Elizabeth Lee},
	Publisher = {American Mathematical Soc.},
	Title = {Markov chains and mixing times},
	Year = {2009}}

@book{kushner2012stochastic,
	Author = {Kushner, Harold Joseph and Clark, Dean S},
	Publisher = {Springer Science \& Business Media},
	Title = {Stochastic approximation methods for constrained and unconstrained systems},
	Volume = {26},
	Year = {2012}}

@article{bach2014adaptivity,
	Author = {Bach, Francis R},
	Journal = {Journal of Machine Learning Research},
	Number = {1},
	Pages = {595--627},
	Title = {Adaptivity of averaged stochastic gradient descent to local strong convexity for logistic regression.},
	Volume = {15},
	Year = {2014}}

@article{Tanner_The_1987,
	Abstract = {Abstract The idea of data augmentation arises naturally in missing value problems, as exemplified by the standard ways of filling in missing cells in balanced two-way tables. Thus data augmentation refers to a scheme of augmenting the observed data so as to make it },
	Author = {Tanner, Martin A and Wong, Wing},
	Doi = {10.1080/01621459.1987.10478458},
	Number = {398},
	Pages = {528-540},
	Title = {The calculation of posterior distributions by data augmentation},
	Volume = {82},
	Year = {1987},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/01621459.1987.10478458}}

@article{Rubin_The_1981,
	Abstract = {Abstract The Bayesian bootstrap is the Bayesian analogue of the bootstrap. Instead of simulating the sampling distribution of a statistic estimating a parameter, the Bayesian bootstrap simulates the posterior distribution of the parameter; operationally and inferentially },
	Author = {Rubin, {DB}},
	Doi = {10.1307/aos/1176345338},
	Journal = {The annals of statistics},
	Title = {The bayesian bootstrap},
	Year = {1981},
	Bdsk-Url-1 = {http://dx.doi.org/10.1307/aos/1176345338}}

@article{Geman_Stochastic_1993,
	Abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field {(MRF)} equivalence, this assignment also determines an {MRF} image model. The energy  ...},
	Author = {Geman, S and Geman, D},
	Doi = {10.1080/02664769300000058},
	Journal = {Journal of Applied Statistics},
	Title = {Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images*},
	Year = {1993},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/02664769300000058}}

@article{Dempster_Maximum_1977,
	Abstract = {A broadly applicable algorithm for computing maximum likelihood estimates from incomplete data is presented at various levels of generality. Theory showing the monotone behaviour of the likelihood and convergence of the algorithm is derived. Many examples are sketched, },
	Author = {Dempster, {AP} and Laird, {NM} and Rubin, {DB}},
	Journal = {Journal of the royal statistical society. {\ldots}},
	Title = {Maximum likelihood from incomplete data via the {EM} algorithm},
	Year = {1977}}

@article{Wei_A_1990,
	Abstract = {Abstract The first part of this article presents the Monte Carlo implementation of the E step of the {EM} algorithm. Given the current guess to the maximizer of the posterior distribution, latent data patterns are generated from the conditional predictive distribution. The expected },
	Author = {Wei, {GCG} and Tanner, {MA}},
	Doi = {10.1080/01621459.1990.10474930},
	Journal = {Journal of the American statistical {\ldots}},
	Title = {A Monte Carlo implementation of the {EM} algorithm and the poor man's data augmentation algorithms},
	Year = {1990},
	Bdsk-Url-1 = {http://dx.doi.org/10.1080/01621459.1990.10474930}}
