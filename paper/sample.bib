%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/


%% Created for Wilson Cai at 2016-12-04 14:09:39 -0800


%% Saved with string encoding Unicode (UTF-8)



@article{duchi2012ergodic,
	Author = {Duchi, John C and Agarwal, Alekh and Johansson, Mikael and Jordan, Michael I},
	Journal = {SIAM Journal on Optimization},
	Number = {4},
	Pages = {1549--1578},
	Publisher = {SIAM},
	Title = {Ergodic mirror descent},
	Volume = {22},
	Year = {2012}}

@book{aldous2002reversible,
	Author = {Aldous, David and Fill, Jim},
	Publisher = {Berkeley},
	Title = {Reversible Markov chains and random walks on graphs},
	Year = {2002}}

@book{levin2009markov,
	Author = {Levin, David Asher and Peres, Yuval and Wilmer, Elizabeth Lee},
	Publisher = {American Mathematical Soc.},
	Title = {Markov chains and mixing times},
	Year = {2009}}

@book{kushner2012stochastic,
	Author = {Kushner, Harold Joseph and Clark, Dean S},
	Publisher = {Springer Science \& Business Media},
	Title = {Stochastic approximation methods for constrained and unconstrained systems},
	Volume = {26},
	Year = {2012}}

@article{bach2014adaptivity,
	Author = {Bach, Francis R},
	Journal = {Journal of Machine Learning Research},
	Number = {1},
	Pages = {595--627},
	Title = {Adaptivity of averaged stochastic gradient descent to local strong convexity for logistic regression.},
	Volume = {15},
	Year = {2014}
}

@article{Tanner_The_1987,
    Author = {Tanner, Martin A and Wong, Wing},
    Doi = {10.1080/01621459.1987.10478458},
    Number = {398},
    Pages = {528-540},
    Title = {The calculation of posterior distributions by data augmentation},
    Volume = {82},
    Year = {1987},
}

@article{Rubin_The_1981,
	Abstract = {Abstract The Bayesian bootstrap is the Bayesian analogue of the bootstrap. Instead of simulating the sampling distribution of a statistic estimating a parameter, the Bayesian bootstrap simulates the posterior distribution of the parameter; operationally and inferentially },
	Author = {Rubin, {DB}},
	Doi = {10.1307/aos/1176345338},
	Journal = {The annals of statistics},
	Title = {The bayesian bootstrap},
	Year = {1981},
}

@article{Geman_Stochastic_1993,
	Abstract = {We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field {(MRF)} equivalence, this assignment also determines an {MRF} image model. The energy  ...},
	Author = {Geman, S and Geman, D},
	Doi = {10.1080/02664769300000058},
	Journal = {Journal of Applied Statistics},
	Title = {Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images*},
	Year = {1993},
}

@article{dempster1977maximum,
  title={Maximum likelihood from incomplete data via the EM algorithm},
  author={Dempster, Arthur P and Laird, Nan M and Rubin, Donald B},
  journal={Journal of the royal statistical society. Series B (methodological)},
  pages={1--38},
  year={1977},
  publisher={JSTOR}
}
@article{Wei1990,
  doi = {10.1080/01621459.1990.10474930},
  url = {http://dx.doi.org/10.1080/01621459.1990.10474930},
  year  = {1990},
  month = {sep},
  publisher = {Informa {UK} Limited},
  volume = {85},
  number = {411},
  pages = {699--704},
  author = {Greg C. G. Wei and Martin A. Tanner},
  title = {A Monte Carlo Implementation of the {EM} Algorithm and the Poor Man's Data Augmentation Algorithms},
  journal = {Journal of the American Statistical Association}
}
@article{Robbins_A_1951,
  pages={400-407},
  title={A stochastic approximation method},
  doi={10.1307/aoms/1177729586},
  author={Robbins, Herbert and Monro, Sutton},
  year={1951},
  abstract={Let M (x) denote the expected value at level x of the response to a certain experiment. M (x) is assumed to be a monotone function of x but is unknown to the experimenter, and it is desired to find the solution x= θ of the equation M (x)= α, where α is a given constant. We give a method for making successive experiments at levels x1, x2,⋯ in such a way that xn will tend to θ in probability.}
}
@article{Polyak_Acceleration_1992,
  title={Acceleration of stochastic approximation by averaging},
  journal={{SIAM} Journal on Control and Optimization},
  author={Polyak, {BT} and Juditsky, {AB}},
  year={1992},
  abstract={A new recursive algorithm of stochastic approximation type with the averaging of trajectories is investigated. Convergence with probability one is proved for a variety of classical optimization and identification problems. It is also demonstrated for these problems that the proposed algorithm achieves the highest possible rate of convergence.}
}
@article{Nedic_Incremental_2001,
  title={Incremental subgradient methods for nondifferentiable optimization},
  journal={{SIAM} Journal on Optimization},
  author={Nedic, A and Bertsekas, {DP}},
  year={2001},
  abstract={We consider a class of subgradient methods for minimizing a convex function that consists of the sum of a large number of component functions. This type of minimization arises in a dual context from Lagrangian relaxation of the coupling constraints of large scale separable problems. The idea is to perform the subgradient iteration incrementally, by sequentially taking steps along the subgradients of the component functions, with intermediate  ...}
}
@incollection{lecun2012efficient,
  title={Efficient backprop},
  author={LeCun, Yann A and Bottou, L{\'e}on and Orr, Genevieve B and M{\"u}ller, Klaus-Robert},
  booktitle={Neural networks: Tricks of the trade},
  pages={9--48},
  year={2012},
  publisher={Springer}
}

@article{Finkel_Efficient_2008,
  title={Efficient, Feature-based, Conditional Random Field Parsing.},
  journal={{ACL}},
  author={Finkel, {JR} and Kleeman, A and Manning, {CD}},
  year={2008},
  abstract={Abstract Discriminative feature-based methods are widely used in natural language processing, but sentence parsing is still dominated by generative methods. While prior feature-based dynamic programming parsers have restricted training and evaluation to artificially short sentences, we present the first general, featurerich discriminative parser, based on a conditional random field model, which has been successfully scaled to the full  ...}
}
@article{Metropolis1953,
  doi = {10.1063/1.1699114},
  url = {http://dx.doi.org/10.1063/1.1699114},
  year  = {1953},
  publisher = {{AIP} Publishing},
  volume = {21},
  number = {6},
  pages = {1087},
  author = {Nicholas Metropolis and Arianna W. Rosenbluth and Marshall N. Rosenbluth and Augusta H. Teller and Edward Teller},
  title = {Equation of State Calculations by Fast Computing Machines},
  journal = {The Journal of Chemical Physics}
}

@ARTICLE{2014Dalalyan,
   author = {{Dalalyan}, A.~S.},
    title = "{Theoretical guarantees for approximate sampling from smooth and log-concave densities}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1412.7392},
 primaryClass = "stat.CO",
 keywords = {Statistics - Computation, Mathematics - Statistics Theory, Statistics - Machine Learning},
     year = 2014,
    month = dec,
   adsurl = {http://adsabs.harvard.edu/abs/2014arXiv1412.7392D},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

